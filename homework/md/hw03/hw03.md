
Q1. **Principles of (functional) programming**

Q1a. Which of the following are programming paradigms? (select three)

[X] Declarative
[X] Functional
[ ] Hadoop
[X] Imperative
[ ] Scala


Q1b. What three concepts characterize a purely functional programming language? (select three)

[X] referential transparency
[ ] input/output
[X] no side effects
[ ] procedural
[X] immutability

Q2. **Big data properties**

Q2a. In lecture we discussed the meaning of the term "Big Data." We decided that, for simplicity, we will call data "big" when it is

( ) at least 1Gb
(X) too big to fit in fast memory (cpu cache + ram) on a single compute node
( ) too big to fit in all computer memory (whether fast or slow)
( ) too big to be dealt with by traditional data-processing software

[[We agreed that a good definition of "Big Data" for our purposes is data that is too large to fit in the fast computer memory of a single machine.  Although Wikipedia has an alternative definition---data that is "too big to be dealt with by traditional data-processing application software"---and while that definition is not wrong, it is not the definition we agreed upon in this class.]]

Q2b. "Big Data" concerns which of the following types of data?

( ) structured
( ) semi-structured
( ) unstructured
(X) all of these

[[Big Data is a blanket term for the data that are too large in size and complex in nature, and which may be structured, unstructured, or semi-structured, and may also be arriving at high velocity.]]

Q2c. JSON and XML are examples of which type of data?

( ) structured
( ) unstructured
(X) semi-structured
( ) none of these

[[Semi-structured data are that which have a structure but do not fit into the relational database. Semi-structured data are organized, which makes it easier for analysis when compared to unstructured data. JSON and XML are examples of semi-structured data.]]

Q2d. Which two of the following statements are true of unstructured data? (select two)

[ ] It is generally easier to analyze than other types of data.
[X] It is often referred to as "messy" data.
[ ] It fits neatly into a schema.
[X] It is the most widespread type of data.
[ ] It is usually found in tables.


Q3. **Latency and fault-tolerance**

Q3a. *Latency* is degradation in performance due to...  (select two)

[ ] a small number of cores in the central processing unit
[X] slow data transfer across the network or cluster
[X] shuffling data between different nodes in a cluster
[ ] failure of one or more nodes in the cluster
[ ] stack overflow caused by recursion

Q3b. Hadoop achieves fault-tolerance by...

( ) using lazy evaluation and garbage collection.
(X) writing intermediate computations to disk.
( ) keeping all data immutable and in-memory.
( ) replaying functional transformations over the original (immutable) dataset.

Q3c. Spark decreases latency while remaining fault-tolerant by... (select three)

[ ] using ideas from imperative programming.
[X] using ideas from functional programming.
[ ] discarding data when it's no longer needed.
[X] keeping all data immutable and in-memory.
[X] replaying functional transformations over the original (immutable) dataset.

Q4. **Transformations and actions**

Q4a. In Spark a *transformation* on an RDD... (select three)

[ ] is eagerly evaluated.
[X] is lazily evaluated.
[ ] immediately computes and returns a result.
[X] does not immediately compute a result.
[X] usually returns another RDD (once it's evaluated).


Q4b. In Spark an *action* on an RDD... (select two)


[X] is eagerly evaluated.
[ ] is lazily evaluated.
[X] immediately computes and returns a result.
[ ] does not immediately compute a result.
[ ] always returns another RDD (once it's evaluated).



Q4c. After performing a series of transformations on an RDD, which of the following methods could you use to make sure those transformations are not repeated (e.g., on each iteration of an algorithm)?

( ) save
(X) persist
( ) memoize
( ) thunk
( ) There is no such method because of the JVM's garbage collection mechanism.



Q4d. Why does Spark's RDD class not have a foldLeft method?

( ) foldLeft can only be performed on lists of Boolean values.
( ) foldLeft doesn't work on immutable collections.
( ) foldLeft is not stack-safe.
( ) foldLeft is not fault-tolerant.
(X) foldLeft is not parallelizable.


Q4e. What is available in Spark's RDD class that overcomes the limitation of foldLeft mentioned in the previous part of this exercise?

(X) aggregate
( ) fold
( ) foldLeft
( ) join
( ) leftOuterJoin

Q5. **Read the docs**

Navigate to the Spark API documentation at

https://spark.apache.org/docs/3.3.1/api/scala/org/apache/spark/index.html

Enter "RDD" in the search box and select RDD from the results that appear on the left.

Q5a. Scroll down the resulting RDD API documentation page and find the cache() method.  What does it say?


(X) Persist this RDD with the default storage level (MEMORY\_ONLY).
( ) Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
( ) Set this RDD's storage level to persist its values across operations after the first time it is computed.
( ) Save this RDD as a SequenceFile of serialized objects.


Q5b. On the RDD API doc page, find the version of persist that takes an argument. What does it say?

( ) Persist this RDD with the default storage level (MEMORY\_ONLY).
( ) Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
(X) Set this RDD's storage level to persist its values across operations after the first time it is computed.
( ) Save this RDD as a SequenceFile of serialized objects.


Q5c. On the RDD API doc page, find the unpersist method.  What does it say?


( ) Persist this RDD with the default storage level (MEMORY\_ONLY).
(X) Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
( ) Set this RDD's storage level to persist its values across operations after the first time it is computed.
( ) Save this RDD as a SequenceFile of serialized objects.


Q5d.  What's the difference between the sample and takeSample methods of the RDD class? (select two)

[ ] sample always uses a with-replacement sampling method, while takeSample always samples without replacement.
[X] sample returns an RDD, while takeSample returns an Array.
[X] The second argument specifies the number of samples desired either as a fraction of the size of the RDD (sample) or as an absolute number (takeSample).
[ ] There is no difference; they are just two different names one can use to invoke the same function.


